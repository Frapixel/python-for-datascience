{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals of Information Systems\n",
    "\n",
    "## Python Programming (for Data Science)\n",
    "\n",
    "### Master's Degree in Data Science\n",
    "\n",
    "#### Gabriele Tolomei\n",
    "<a href=\"mailto:gtolomei@math.unipd.it\">gtolomei@math.unipd.it</a><br/>\n",
    "University of Padua, Italy<br/>\n",
    "2018/2019<br/>\n",
    "December, 3 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 11: A Machine Learning Primer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "-  There exist several definitions of _what_ is **Machine Learning** (**ML**):\n",
    "\n",
    "    1. \"A computer program is said to **learn from experience** _E_ with respect to some class of tasks _T_ and performance measure _P_ if its performance at tasks in _T_, as measured by _P_, improves with experience _E_.\" ([Tom Mitchell](http://www.cs.cmu.edu/~tom/mlbook.html)) \n",
    "    2.  \"ML is an application of artificial intelligence (AI) that provides systems the ability to **automatically learn** and improve from experience (i.e., _observed data_) **without being explicitly programmed**\" ([source](http://www.expertsystem.com/machine-learning-definition/)).\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Just Take a Step Back\n",
    "\n",
    "-  Traditionally, we design computer programs to solve specific tasks which would otherwise require a huge human effort.\n",
    "\n",
    "-  For example, consider the task of creating a vocabulary of words from a collection of text documents.\n",
    "\n",
    "-  To do so, we need to be able to build an **algorithm** which solves the task we aim to perform.\n",
    "\n",
    "-  In other words, we have to _mathematically encode_ our task into a **computable function** which takes some **input** (e.g., a collection of text documents) and returns some **output** (e.g., a vocabulary of words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different Types of Tasks\n",
    "\n",
    "-  Some tasks, however, simply **cannot** be pinpointed down mathematically, as the function they encode to is just too hard to be implemented in a traditional computer program.\n",
    "\n",
    "-  Consider how would you possibly write a computer program, which given as input an image gets as output a boolean answer that tells whether the image contains or not a bird...\n",
    "\n",
    "-  **Idea**: Access to a collection of, say, 1M images each one with a **label** associated (e.g., <code>**bird**</code>/<code>**no_bird**</code>) and output a computer program that detects birds in images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## xkcd Tells Us Better!\n",
    "\n",
    "<center>![](./img/xkcd_ml_1.png)</center>\n",
    "\n",
    "<center>([Image Source](https://xkcd.com/1425/))</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Taxonomy of ML\n",
    "\n",
    "-  Roughly speaking there are two main **categories** of ML tasks:\n",
    "\n",
    "    1.  **Supervised Learning**: Given a set of **labeled** examples, **predict** the labels of _new and unseen_ examples\n",
    "    2.  **Unsupervised Learning**: Given a set of examples, **find structure** in the data (e.g., _clusters_, _subspaces_, _manifolds_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning\n",
    "\n",
    "-  We can further divide supervised learning into two sub-categories, depending on the **label** we want to predict.\n",
    "\n",
    "    -  **Regression**: if the label takes on _continuous_ values\n",
    "    -  **Classification**: if the label takes on _discrete_ values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning: Regression vs. Classification\n",
    "\n",
    "-  **Regression**:\n",
    "    - value of a house\n",
    "    - probability of click on a link to a web page\n",
    "        \n",
    "-  **Classification**:\n",
    "    -  spam _vs._ non-spam emails (**binary classification**)\n",
    "    -  movie ratings on a 1 to 5 scale (**k-ary or multiclass classification**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The General (Supervised) ML Pipeline\n",
    "\n",
    "0) Be sure your problem needs _actually_ to be tackled using ML!\n",
    "\n",
    "1) **Data Collection**: Get **labeled data** from the domain of your interest (may be the hardest part!)\n",
    "\n",
    "2) **Feature Engineering**: Represent your data with a \"machine-friendly\" format\n",
    "\n",
    "3) **Model Training**: Build one (or more) **learning models** (more on this later)\n",
    "\n",
    "4) **Model Selection/Evaluation**: Pick the best-performing model according to some **quality metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "-  Any ML technique requires data to operate on!\n",
    "\n",
    "-  Supervised Learning, in particular, needs **labeled data**, which may be even harder to get (e.g., a set of emails with <code>**spam**</code>/<code>**non_spam**</code> tags).\n",
    "\n",
    "-  Most of the time, this step involves combining multiple and possibly heterogeneous data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "-  Collected data must be encoded to a **machine-readable** format.\n",
    "\n",
    "-  Each object of our problem domain is transformed into an $n$-dimensional **feature vector**.\n",
    "\n",
    "-  Each **feature** captures a specific property of the object we believe it is useful to \"separate\" different objects.\n",
    "\n",
    "-  In the following, we refer to **instance** (or **example**) to identify the feature vector of an object **and** its associated label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Characteristics of Features\n",
    "\n",
    "-  Feature values can be either **categorical** (e.g., _gender_) or **continuous** (e.g., _weight_).\n",
    "\n",
    "-  A feature can be derived _locally_ from a single object (e.g., the _annual salary_ of a person)\n",
    "\n",
    "-  Or it can result from more complex computation on the whole data collection (e.g., the _tf-idf_ score of a word in a document computed against a corpus of documents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: _spam_ vs. _non-spam_ emails\n",
    "</p>\n",
    "<center>![](./img/ml_feature_engineering.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges and Solutions\n",
    "\n",
    "-  **Problem**: Collected data is far from being perfect!\n",
    "\n",
    "-  Many challenges need to be addressed before moving down to next stages of the ML pipeline.\n",
    "\n",
    "-  Overall, this is accomplished with an intermediate **Data Preprocessing** step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Values\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_na.png)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Managing Data Sparsity\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_sparsity.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Outliers\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_outliers.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mixing Categorical and Continuous Feature Values\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_catcon.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different Feature Scales\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_scale.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Managing Imbalance\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_imbalance.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relationship between Features\n",
    "</p>\n",
    "<center>![](./img/ml_preprocessing_collinearity.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Bit of Notation\n",
    "\n",
    "-  We denote by $\\mathcal{D} = \\{({\\textbf{x}_1}, y_1), ({\\textbf{x}_2}, y_2), \\ldots, ({\\textbf{x}_m}, y_m)\\}$ our resulting labeled dataset.\n",
    "\n",
    "-  This is made of $m$ **instances**; the $i$-th instance is represented by the tuple $({\\textbf{x}_i}, y_i)$, where:\n",
    "    -  ${\\textbf{x}_i} \\in \\mathbb{R}^n$ is an $n$-dimensional **feature vector**, i.e., ${\\textbf{x}_i} = (x_{i,1}, \\ldots,x_{i,n})^T$\n",
    "    -  $y_i \\in \\mathbb{R}$ if the label is **continuous** (**regression**) or $y_i \\in \\{1, 2, \\ldots, k\\}$ if the label is **categorical** and takes on $k$ values (**k-ary classification**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Labeled Dataset\n",
    "</p>\n",
    "<center>![](./img/ml_labeled_dataset_1.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Bit of Notation\n",
    "\n",
    "-  We indicate by $X\\in \\mathbb{R}_{m,n}$ the $m$-by-$n$ **feature matrix** resulting from the $m$ $n$-dimensional feature vectors.\n",
    "\n",
    "-  Similarly, we denote by $Y$ the $m$-dimensional vector containing instance labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Labeled Dataset\n",
    "</p>\n",
    "<center>![](./img/ml_labeled_dataset_2.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intuition\n",
    "\n",
    "-  **Idea**: There exists an **unknown target function** $f$, which maps element of $X$ to elements of $Y$.\n",
    "$$\n",
    "f = X \\mapsto Y\n",
    "$$\n",
    "\n",
    "-  Unfortunately, we cannot just write down an algorithm that implements $f$.\n",
    "\n",
    "-  Still, we can try to _**learn**_ $f$, namely to find another function $h^*$ which approximates the _true_ $f$ ($h^* \\approx f$) using the data $\\mathcal{D}$ we observed.\n",
    "\n",
    "-  We refer to $h^*$ as our **hypothesis** (used to approximate $f$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Do We Select $h^*$ From?\n",
    "\n",
    "-  We choose $h^*$ from a family of functions $\\mathcal{H}$, called the **hypothesis space**.\n",
    "\n",
    "-  To actually pick $h^*$, we need to further specifying two components:\n",
    "    -  the **loss function** (a.k.a. **cost function**) denoted by $\\ell$\n",
    "    -  the **learning algorithm** denoted by $\\mathcal{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Loss Function $\\ell$\n",
    "\n",
    "-  Measures the error we would make if a hypothesis $h$ is used instead of the true $f$.\n",
    "\n",
    "-  Such an error can be computed _only_ on the data we observed (i.e., on $\\mathcal{D}$).\n",
    "\n",
    "-  Therefore, it depends on the hypothesis _and_ the dataset, i.e., $\\ell: \\mathcal{H}\\times \\mathcal{D}\\mapsto \\mathbb{R}$.\n",
    "\n",
    "-  We should use this **in-sample error** (a.k.a. **empirical loss**) as an **_estimate_** of the **out-of-sample error** (a.k.a. **expected loss** or **risk**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Learning Algorithm $\\mathcal{A}$\n",
    "\n",
    "-  Defines the strategy we use to search the hypothesis space $\\mathcal{H}$ for picking our **best** hypothesis $h^* \\in \\mathcal{H}$.\n",
    "\n",
    "-  Here, \"**best**\" means the hypothesis that **minimizes** the loss function on the observed data (**Empirical Risk Minimization**).\n",
    "\n",
    "-  In other words, among all the hypotheses specified by $\\mathcal{H}$, the learning algorithm will pick the one that minimizes $\\ell$.\n",
    "\n",
    "$$\n",
    "h^* = \\text{argmin}_{h\\in \\mathcal{H}} \\ell(h, \\mathcal{D})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-Slide ML\n",
    "</p>\n",
    "<center>![](./img/ml_overview.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Hypothesis Space $\\mathcal{H}$\n",
    "\n",
    "-  Intuitively, the larger the hypothesis space:\n",
    "    - the larger will be the set of functions that can be represented (**<span style=\"color:green\">+</span>**)\n",
    "    - the harder will be for the learning algorithm to pick the best $h^*$ (**<span style=\"color:red\">-</span>**)\n",
    "    \n",
    "-  **Trade-off**: Put some constraints on $\\mathcal{H}$, e.g., limit the search space $\\mathcal{A}$ has to explore only to **linear functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example of $\\mathcal{H}$: Linear Models\n",
    "\n",
    "-  The underlying assumption here is that there exists a **linear relationship** between $X$ (**features**) and $Y$ (**class label**/**value**).\n",
    "\n",
    "$$\n",
    "\\mathcal{H} = \\{h_{\\boldsymbol{\\theta}}: X \\longmapsto Y~|~h_{\\boldsymbol{\\theta}}(\\textbf{x}) = \\theta_0x_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n\\}\n",
    "$$\n",
    "\n",
    "-  $\\boldsymbol{\\theta}$ is called the **vector of parameters** (of the linear model).\n",
    "\n",
    "- $x_0 = 1$ by convention.\n",
    "\n",
    "-  Among all the possible instantiations of $\\boldsymbol{\\theta}$, the learning algorithm will pick $\\boldsymbol{\\theta}^*$ as the one which minimizes the **loss function** $\\ell$ computed on $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Possible Loss Function: _Mean Squared Error_ (MSE)\n",
    "\n",
    "-  **MSE** is just a possible (mathematically convenient) choice of loss function $\\ell$.\n",
    "\n",
    "-  **MSE** measures the average error when the true target $f$ is replaced with a hypothesis $h_{\\boldsymbol{\\theta}}\\in \\mathcal{H}$ on the observed data $\\mathcal{D}$.\n",
    "\n",
    "$$\n",
    "\\ell(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{m}\\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - f(\\textbf{x}_i)\\Big)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{m}\\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i \\Big)^2\n",
    "$$\n",
    "\n",
    "-  Each term of the above summation, i.e., $\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i\\Big)^2$, represents the **squared error** w.r.t. a single instance in $\\mathcal{D}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Learning Algorithm (Revisited)\n",
    "\n",
    "-  Reduces the learning problem to an **optimization problem**.\n",
    "\n",
    "-  Among all the possible $h_{\\boldsymbol{\\theta}} \\in \\mathcal{H}$, it picks $h^* = h_{\\boldsymbol{\\theta}^*}$, so as to minimize the loss function.\n",
    "\n",
    "$$\n",
    "h^* = \\texttt{argmin}_{\\boldsymbol{\\theta}} \\{\\ell(h_{\\boldsymbol{\\theta}}, \\mathcal{D})\\}\n",
    "$$\n",
    "-  In particular, if $\\ell = \\textsf{MSE}$:\n",
    "\n",
    "$$\n",
    "h^* = \\texttt{argmin}_{\\boldsymbol{\\theta}} \\{\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})\\} = \n",
    "\\texttt{argmin}_{\\boldsymbol{\\theta}} \\Bigg \\{\\frac{1}{m} \\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i \\Big)^2\\Bigg \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimum and Maximum of a Function: First Derivative\n",
    "\n",
    "-  Whenever we want to find the minimum (maximum) of a real-valued function $f: \\mathbb{R} \\longmapsto \\mathbb{R}$, we look for **stationary points**, i.e., the set of points $S = \\{(x, f(x))~|~f'(x) = 0\\}$ where the first derivative is 0.\n",
    "\n",
    "-  Note that depending on the shape of the function $f$, a stationary point doesn't necessarily correspond to a local minimum (maximum) but it may be a **point of inflection**.\n",
    "\n",
    "-  To investigate better what happens at a specific stationary point, we need to check the second derivative $f''(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimum and Maximum of a Function: Second Derivative\n",
    "\n",
    "-  Given a stationary point $(x_s, f(x_s))\\in S$:\n",
    "    -  if $f''(x_s) > 0$ then $(x_s, f(x_s))$ is a **local minimum**\n",
    "    -  if $f''(x_s) < 0$ then $(x_s, f(x_s))$ is a **local maximum**\n",
    "    -  if $f''(x_s) = 0$ then $(x_s, f(x_s))$ may be an **inflection point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimum and Maximum of a Convex/Concave Function\n",
    "\n",
    "-  Any local minimum (maximum) of a **convex** (**concave**) function is also a **global** minimum (maximum).\n",
    "\n",
    "-  If we know the function is **convex** (**concave**) finding the minimum (maximum) can be done just by computing the first derivative and set it to 0.\n",
    "\n",
    "-  In the case of a multivariate function, this generalizes to compute the **gradient** ($\\nabla$) of the function and set it to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Gradient $\\nabla$\n",
    "\n",
    "-  The gradient of a multivariate function $f: \\mathbb{R}^n \\longmapsto \\mathbb{R}$ is the $n$-dimensional vector of the **partial derivatives** of the function w.r.t. each of its variable.\n",
    "\n",
    "$$\n",
    "\\nabla f = \\Bigg(\\frac{\\partial{f}}{\\partial{x_1}}, \\frac{\\partial{f}}{\\partial{x_2}}, \\ldots, \\frac{\\partial{f}}{\\partial{x_n}} \\Bigg)\n",
    "$$\n",
    "\n",
    "-  Solving $\\nabla f = \\mathbf{0}$ means finding an $n$-dimensional vector resulting from the following:\n",
    "\n",
    "$$\n",
    "\\nabla f =\\Bigg(\\frac{\\partial{f}}{\\partial{x_1}}, \\frac{\\partial{f}}{\\partial{x_2}}, \\ldots, \\frac{\\partial{f}}{\\partial{x_n}}\\Bigg) = (\\underbrace{0, 0, \\ldots, 0}_{n}) = \\mathbf{0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$ is a Convex Function\n",
    "\n",
    "-  Each term of the summation of $\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$ is a multivariate linear function of the model parameters $\\boldsymbol{\\theta} = (\\theta_0, \\theta_1, \\ldots, \\theta_n)$.\n",
    "\n",
    "-  Linear functions are **convex**, and so does the square of a convex function; also, the sum of convex functions is again convex.\n",
    "\n",
    "-  Convex functions have a **unique local minimum**, which therefore happens to be the **global minimum**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize The Optimization Problem\n",
    "</p>\n",
    "<center>![](./img/ml_mse_convex.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE\n",
    "\n",
    "-  The following is the expression of the gradient of $\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) \n",
    "= \\nabla \\Bigg [\\frac{1}{m} \\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i\\Big)^2\\Bigg ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) \n",
    "= \\nabla \\Bigg [\\frac{1}{m} \\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i\\Big)^2\\Bigg ]\n",
    "$$\n",
    "\n",
    "-  Due to the **scalar multiple rule** and **sum rule** of the derivative, i.e., $\\frac{\\partial{f}}{\\partial{t}}(\\alpha t) = \\alpha \\frac{\\partial{f}}{\\partial{t}}$ ($\\alpha \\in \\mathbb{R}$, constant) and $\\frac{\\partial{f}}{\\partial{t}}\\Big(\\sum t \\Big) = \\sum \\Big(\\frac{\\partial{f}}{\\partial{t}} \\Big)$, we can rewrite the above as follows:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\frac{1}{m} \\Bigg [\\sum_{i=1}^m \\nabla \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i\\Big)^2 \\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE (single instance)\n",
    "\n",
    "-  To make things easier, let's consider for a moment the special case where $\\mathcal{D}$ contains just a **single** instsance, i.e., $\\mathcal{D} = \\{(\\mathbf{x}, y)\\}$. Therefore:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\nabla \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}) - y\\Big)^2\n",
    "$$\n",
    "\n",
    "-  Due to the **power rule** and **chain rule** of the derivative, i.e., $\\frac{\\partial{f(t^{\\alpha})}}{\\partial{t}} = \\alpha t^{\\alpha-1}$ $\\frac{\\partial{f(g(t))}}{\\partial{t}}\n",
    "= \\frac{\\partial{f(g(t))}}{\\partial{g(t)}} \\cdot \\frac{\\partial{g(t)}}{\\partial{t}}$, we can rewrite the above as follows:\n",
    "\n",
    "$$\n",
    "= 2 \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}) - y\\Big) \\nabla\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}) -y \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE (single instance)\n",
    "\n",
    "\n",
    "$$\n",
    "\\nabla\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}) - y \\Big)\n",
    "= \\nabla \\Big(\\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n - y \\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\Big(\\frac{\\partial{(\\theta_0 x_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n - y)}}{\\partial{\\theta_0}}, \\frac{\\partial{(\\theta_0 x_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n - y)}}{\\partial{\\theta_1}}, \\ldots, \\frac{\\partial{(\\theta_0 x_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n - y\n",
    ")}}{\\partial{\\theta_n}}\\Big)\n",
    "= \\Big(x_0, x_1, \\ldots, x_n\\Big) = \\mathbf{x}\n",
    "$$\n",
    "\n",
    "-  Overall:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = 2 \\underbrace{\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}) - y\\Big)}_{\\textrm{scalar}} \\cdot \\underbrace{\\textbf{x}}_{(n+1)\\textrm{-dimensional vector}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE (single instance)\n",
    "\n",
    "-  We can rewrite the formula above using **vectorized notation**, noticing that $h_{\\boldsymbol{\\theta}}(\\textbf{x}) = \\theta_0 x_0 + \\theta_1 x_1 + \\ldots \\theta_n x_n = \\boldsymbol{\\theta}^T \\mathbf{x}$.\n",
    "\n",
    "-  $\\boldsymbol{\\theta}^T \\mathbf{x}$ is obviously a scalar which results from the dot product of a $1$-by-$(n+1)$ row vector $\\boldsymbol{\\theta}^T$ and an $(n+1)$-by-$1$ column vector $\\mathbf{x}$.\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = 2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y) \\cdot \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE (single instance)\n",
    "\n",
    "-  The product of a vector by a scalar is applied element-wise, therefore: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) &= \\begin{bmatrix}\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_0 \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_1  \\\\\n",
    "           \\vdots \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_n \n",
    "         \\end{bmatrix}\n",
    "         ~=~ \\begin{bmatrix}\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y) \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_1  \\\\\n",
    "           \\vdots \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_n \n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$\n",
    "as we set $x_0 = 1$.\n",
    "\n",
    "-  Note that $\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$ is an $(n+1)$-dimensional vector, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting the Gradient of MSE to 0 (single instance)\n",
    "\n",
    "-  To find the local minimum (which is also global) of $\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$, we set:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) &= \\begin{bmatrix}\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y) \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_1  \\\\\n",
    "           \\vdots \\\\\n",
    "           2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_n \n",
    "         \\end{bmatrix}\n",
    "         ~=~\n",
    "         \\begin{bmatrix}\n",
    "           0 \\\\\n",
    "           0  \\\\\n",
    "           \\vdots \\\\\n",
    "           0 \n",
    "         \\end{bmatrix}\n",
    "         ~=~\\mathbf{0}\n",
    "  \\end{align}\n",
    "$$\n",
    "\n",
    "-  Therefore, we have to solve a system of $n+1$ linear equations of $n+1$ variables, each equation of the form $2 (\\boldsymbol{\\theta}^T \\mathbf{x} - y)\\cdot x_j = 0$, $j \\in \\{0, 1, \\ldots, n\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE ($m$ instances)\n",
    "\n",
    "-  Going back to the overall **MSE** in the general case where $\\mathcal{D}$ contains $m$ instances:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\frac{1}{m} \\Bigg\\{\\Bigg[ 2 \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_1) - y_1\\Big) \\nabla\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_1) -y_1 \\Big)\\Bigg] +\n",
    "$$\n",
    "$$\n",
    "\\ldots\n",
    "$$\n",
    "$$\n",
    "+ \n",
    "\\Bigg[ 2 \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_m) - y_m\\Big) \\nabla\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_m) -y_m \\Big)\\Bigg] \\Bigg\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{2}{m} \\Bigg [\\sum_{i=1}^m \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) -y_i\\Big) \\nabla \\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) -y_i\\Big)  \\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE ($m$ instances)\n",
    "\n",
    "- Putting all together:\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\frac{2}{m} \\Bigg [\\sum_{i=1}^m \\underbrace{\\Big(h_{\\boldsymbol{\\theta}}(\\textbf{x}_i) - y_i\\Big)}_{\\textrm{scalar}} \\cdot \\underbrace{\\textbf{x}_i}_{(n+1)\\textrm{-dimensional vector}}  \\Bigg]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) &= \\begin{bmatrix}\n",
    "           \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) \\cdot x_{1,0} + \\ldots + \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\cdot x_{m,0} \\\\\n",
    "           \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) \\cdot x_{1,1} + \\ldots + \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\cdot x_{m,1}  \\\\\n",
    "           \\vdots \\\\\n",
    "           \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) \\cdot x_{1,n} + \\ldots + \\frac{2}{m} (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\cdot x_{m,n} \n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient of MSE ($m$ instances)\n",
    "\n",
    "-  Note that we have introduced a second subscript to be able to index each feature's instance within $\\mathcal{D}$, i.e., $x_{i,j}$.\n",
    "\n",
    "-  Moreover, we have set all $x_{i, 0} = 1~(i \\in \\{1, \\ldots, m\\})$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) &= \\frac{2}{m}~\\begin{bmatrix}\n",
    "           (\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) + \\ldots +  (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\\\\n",
    "            (\\boldsymbol{\\theta}^T \\mathbf{x_1}- y_1) \\cdot x_{1,1} + \\ldots + (\\boldsymbol{\\theta}^T \\mathbf{x_m}- y_m) \\cdot x_{m,1}  \\\\\n",
    "           \\vdots \\\\\n",
    "          (\\boldsymbol{\\theta}^T \\mathbf{x_1}- y_1) \\cdot x_{1,n} +  \\ldots + (\\boldsymbol{\\theta}^T \\mathbf{x_m}- y_m) \\cdot x_{m,n} \n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting the Gradient of MSE to 0 ($m$ instances)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\underbrace{\\frac{2}{m}~\\begin{bmatrix}\n",
    "           (\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) + \\ldots +  (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\\\\n",
    "            (\\boldsymbol{\\theta}^T \\mathbf{x_1}- y_1) \\cdot x_{1,1} + \\ldots + (\\boldsymbol{\\theta}^T \\mathbf{x_m}- y_m) \\cdot x_{m,1}  \\\\\n",
    "           \\vdots \\\\\n",
    "          (\\boldsymbol{\\theta}^T \\mathbf{x_1}- y_1) \\cdot x_{1,n} + \\ldots + (\\boldsymbol{\\theta}^T \\mathbf{x_m}- y_m) \\cdot x_{m,n} \n",
    "         \\end{bmatrix}}_{\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})}\n",
    "         ~=~\n",
    "         \\begin{bmatrix}\n",
    "           0 \\\\\n",
    "           0  \\\\\n",
    "           \\vdots \\\\\n",
    "           0 \n",
    "         \\end{bmatrix}\n",
    "         ~=~\\mathbf{0}\n",
    "  \\end{align}\n",
    "$$\n",
    "\n",
    "-  Again, we have to solve a system of $n+1$ linear equations of $n+1$ variables, each equation of the form $\\frac{2}{m} \\Big[(\\boldsymbol{\\theta}^T \\mathbf{x_1} - y_1) \\cdot x_{1,j} + \\ldots + (\\boldsymbol{\\theta}^T \\mathbf{x_m} - y_m) \\cdot x_{m,j}\\Big] = 0$, $j \\in \\{0, 1, \\ldots, n\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorized Form of the Gradient of MSE\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "           x_{1,0}, x_{1,1}, \\ldots, x_{1,n} \\\\\n",
    "           x_{2,0}, x_{2,1}, \\ldots, x_{2,n} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{m,0}, x_{m,1}, \\ldots, x_{m,n} \\\\ \n",
    "         \\end{bmatrix}}_{\\textbf{feature matrix}~\\mathbf{X}_{m,n+1}}\n",
    "         ~\n",
    "         \\underbrace{\\begin{bmatrix}\n",
    "           \\theta_{0} \\\\\n",
    "           \\theta_{1}  \\\\\n",
    "           \\vdots \\\\\n",
    "           \\theta_{n} \\\\ \n",
    "         \\end{bmatrix}}_{\\textbf{parameter vector} ~\\boldsymbol{\\theta}}\n",
    "         ~\n",
    "         \\underbrace{\\begin{bmatrix}\n",
    "           y_1 \\\\\n",
    "           y_2  \\\\\n",
    "           \\vdots \\\\\n",
    "           y_{m} \\\\ \n",
    "         \\end{bmatrix}}_{\\textbf{label vector}~\\mathbf{y}_{m,1}}\n",
    "  \\end{align}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorized Form of the Gradient of MSE\n",
    "\n",
    "$$\n",
    "\\nabla \\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D}) = \\frac{2}{m} \\mathbf{X}^T(\\mathbf{X}\\cdot \\boldsymbol{\\theta} - \\mathbf{y})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{2}{m} \\mathbf{X}^T(\\mathbf{X}\\cdot \\boldsymbol{\\theta} - \\mathbf{y}) = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^T\\cdot \\mathbf{X}\\cdot \\boldsymbol{\\theta} = \\mathbf{X}^T\\cdot \\mathbf{y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} = \\mathbf{X}^{\\dagger}\\cdot \\mathbf{y},~\\textrm{where } \\mathbf{X}^{\\dagger} = (\\mathbf{X}^T\\cdot \\mathbf{X})^{-1} \\cdot \\mathbf{X}^T~\\textrm{is the }\\textbf{pseudo-inverse }\\textrm{of }\\mathbf{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional Notes\n",
    "\n",
    "-  Luckily, there exists a closed-form solution to the convex optimization problem above (i.e., to minimize **MSE**).\n",
    "\n",
    "-  However, other choices of loss functions (even if convex) may need an **iterative** approach to get to a (local) minimum.\n",
    "\n",
    "-  For example, **gradient descent** use the gradient to **iteratively** converge to a local minimum (guaranteed for convex loss functions).\n",
    "\n",
    "-  We should use gradient descent as the size of our problem increases because computing the inverse of a large matrix is generally a very costly task ($O(n^3)$, where $n\\times n$ is the size of the matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "-  A generic iterative algorithm used to find an approximate solution to an optimization problem.\n",
    "\n",
    "-  It consists of 3 parameters:\n",
    "    -  $\\boldsymbol{\\theta}_0\\in \\mathbb{R}^n$ as the **initial (random) guess**\n",
    "    -  $\\epsilon > 0$ **stopping criterion** \n",
    "    -  $\\alpha$ **step size**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent: The Algorithm\n",
    "\n",
    "1.  $\\boldsymbol{\\theta}^* = \\boldsymbol{\\theta}_0$;\n",
    "\n",
    "2.  <code>**while**</code> $||\\nabla f||_2 > \\epsilon$: // _replace $f$ with the function of interest, e.g.,_ $\\textsf{MSE}(h_{\\boldsymbol{\\theta}}, \\mathcal{D})$\n",
    "\n",
    "    $\\boldsymbol{\\theta}^* = \\boldsymbol{\\theta}^* - \\underbrace{\\alpha}_{\\textrm{step size}} \\nabla f(\\boldsymbol{\\theta}^*)$; // _the direction of greatest decrease of $f$ is opposite to the gradient vector_\n",
    "    \n",
    "3. <code>**return**</code> $\\boldsymbol{\\theta}^*$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent: The Choice of $\\boldsymbol{\\theta}_0$\n",
    "\n",
    "-  The starting point $\\boldsymbol{\\theta}_0$ can be chosen arbitrarily, though for non-convex function $f$ the output of gradient descent can vary with its choice. \n",
    "\n",
    "-  For convex $f$, gradient descent will converge toward the **same point**, i.e., the global minimum, independently of the starting point.\n",
    "\n",
    "-  The choice of starting point can still affect the number of iterations until convergence.\n",
    "\n",
    "-  In practice, one should choose $\\boldsymbol{\\theta}_0$ according to our best guess as to where the global minimum is likely to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent: The Choice of $\\epsilon$\n",
    "\n",
    "-  The parameter $\\epsilon$ determines the stopping criterion. \n",
    "\n",
    "-  Note that since $\\epsilon > 0$, gradient descent generally does not halt at an **actual** local minimum, but rather at some kind of \"approximate local minimum\".\n",
    "\n",
    "-  Smaller values of $\\epsilon$ mean more iterations before stopping but a higher-quality solution at termination. \n",
    "\n",
    "-  In practice, one tries various values of $\\epsilon$ to achieve the right balance between computation time and solution quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent: The Choice of $\\alpha$\n",
    "\n",
    "-  The final parameter $\\alpha$, the \"step size\", is perhaps the most important. \n",
    "\n",
    "-  While gradient descent is flexible enough that different values of $\\alpha$ can be used in different iterations, in practice one typically sets $\\alpha$ in advance and stick to it over all iterations.\n",
    "\n",
    "-  The \"best\" value of $\\alpha$ is typically chosen by experimentation. For example, we can run the entire gradient descent algorithm with a few different choices of $\\alpha$ to see which run gives us the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Overfitting (High Variance)\n",
    "\n",
    "-  Minimizing the loss function considering the whole dataset $\\mathcal{D}$ just limits the **in-sample error**.\n",
    "\n",
    "-  Our ultimate goal is to pick a hypothesis $h^*$ which is able to **generalize** to unseen instances (i.e., minimize the **out-of-sample error**).\n",
    "\n",
    "-  Note that if we pick a hypothesis that just memorizes all the instances in $\\mathcal{D}$, this will have a 0 **in-sample error** but this is **not** learning!\n",
    "\n",
    "-  **Overfitting**: $h^*$ is not learning the true $f$ but just mimic random noise\n",
    "-  **High Variance**: $h^*$ does not generalize, as it strongly depends on $\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Underfitting (High Bias)\n",
    "\n",
    "-  Anyway, we don't want $h^*$ to perform poorly on $\\mathcal{D}$.\n",
    "\n",
    "-  **Underfitting**: $h^*$ has a very high in-sample error\n",
    "-  **High Bias**: $h^*$ does not take advantage of $\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias-Variance Tradeoff\n",
    "</p>\n",
    "<center>![](./img/ml_bias_variance.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting the Dataset $\\mathcal{D}$\n",
    "\n",
    "-  To prevent overfitting, split the dataset into (at least) two separate random samples:\n",
    "    -  **Training Set** ($\\mathcal{D}_{\\textrm{train}}$) used to learn $h^*$, such that $|\\mathcal{D}_{\\textrm{train}}|$ = 0.8 $|\\mathcal{D}|$\n",
    "    -  **Test** or **Held-out Set** ($\\mathcal{D}_{\\textrm{test}}$) used to evaluate $h^*$, such that $|\\mathcal{D}_{\\textrm{test}}|$ = $|\\mathcal{D}| - |\\mathcal{D}_{\\textrm{train}}|$\n",
    "    \n",
    "-  Note that the (*offline* or *online*) metrics we use to evaluate $h^*$ do not necessarily have to be the same of that we optimize at training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting the Dataset $\\mathcal{D}$\n",
    "</p>\n",
    "<center>![](./img/ml_dataset_splitting.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Much Data Do We Need?\n",
    "\n",
    "-  In general, the more data we have the better we learn.\n",
    "\n",
    "-  Even if the datasets we operate on are not so big, we can still take advantage of ML.\n",
    "\n",
    "-  For example, we can use a technique called $k$-**fold cross validation** (e.g., $k=10$) instead of just splitting $\\mathcal{D}$ in two datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$-fold Cross Validation\n",
    "\n",
    "-  (Optional) Split the dataset in $\\mathcal{D}_{\\textrm{train}}$ and $\\mathcal{D}_{\\textrm{test}}$, as discussed above. \n",
    "\n",
    "-  Repeat for $k$ iterations the following step:\n",
    "\n",
    "    -  Randomly select a proportion of $1/k$ instances from $\\mathcal{D}_{\\textrm{train}}$ which will be used for testing, whilst the remaining $(k-1)/k$ proportion of the dataset is used for training.\n",
    "    -  Compute the error on the test proportion.\n",
    "\n",
    "-  Eventually, compute the **cross validation** error as the average of the individual errors obtained in each of the $k$ runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Model Selection/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which Model Should I Use?\n",
    "\n",
    "-  Several learning models are designed to achieve the same tasks.\n",
    "\n",
    "-  Each learning model has its own set of parameters, a.k.a. **hyperparameters** (e.g., the number $k$ of neighbors in $k$NN).\n",
    "\n",
    "<center>![](./img/ml_models.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation Set\n",
    "\n",
    "-  It is crucial not to mix model training with hyperparameter sweeping.\n",
    "\n",
    "-  Another portion of the original dataset (**Validation Set**) should be reserved for this task.\n",
    "\n",
    "-  This can be also done within each step of a $k$-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "Suppose we want to select which value of $k \\in \\{2, 5, 10\\}$ of a $k$NN gives the best performance.\n",
    "\n",
    "1.  Train a separate model for each value of $k$ on the training set (e.g., 70%)\n",
    "\n",
    "2.  Measure the error of each model on the validation set (e.g., 10%)\n",
    "\n",
    "3.  Select the model whose value of $k$ gives the best performance on the validation set (e.g., $k = 5$)\n",
    "\n",
    "4.  Re-train **only** this model on the training + validation sets\n",
    "\n",
    "5.  Measure the performance on the test set (e.g., 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example Using Cross Validation\n",
    "\n",
    "1.  For each cross validation run:\n",
    "    -  Train a separate model for each value of $k$ on the training set portion of that run\n",
    "    -  Measure the error of each model on the validation set portion of that run\n",
    "\n",
    "2.  Select the model whose value of $k$ gives the best performance on the 10 averaged validation sets (e.g., $k = 5$)\n",
    "\n",
    "3.  Re-train **only** this model on the whole training set (e.g., 80%)\n",
    "\n",
    "4.  Measure the performance on the test set (e.g., 20%)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
