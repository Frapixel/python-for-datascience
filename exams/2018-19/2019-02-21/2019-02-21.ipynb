{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b622aa00a88beb1f25bffa2285e37a9d",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# 2019-02-21 Exam\n",
    "\n",
    "### General Instructions:\n",
    "\n",
    "Welcome to the **Python Programming (for Data Science)** exam session! Please, read **carefully** the instructions below before start writing code. \n",
    "\n",
    "This session will last **75 minutes** and is divided into **two parts**: one about \"general\" Python programming and the other about Python programming for Data Science. Each part is made of a set of exercises, which globally accounts for **16** + **16** = **32 points**.\n",
    "You will earn all of the points associated to an exercise **if and only if** the answer you provide passes successfully **all** the tests (both those that are visible and those that are hidden to you).<br />\n",
    "\n",
    "To actually write down your implementation, make sure to fill in any place that says <code style=\"color:green\">**_# YOUR CODE HERE_**</code>. Note also that you should **either comment or delete** any <code style=\"color:green\">**raise NotImplementedError()**</code> exception.<br />\n",
    "\n",
    "For this exam session **you will not be allowed** to use any lecture material yet you will be able to access the following APIs:\n",
    "\n",
    "-  [Python](https://docs.python.org/3.6/library/index.html)\n",
    "-  [Numpy](https://docs.scipy.org/doc/numpy-1.13.0/reference/)\n",
    "-  [Scipy](https://docs.scipy.org/doc/scipy-1.0.0/reference/)\n",
    "-  [Pandas](https://pandas.pydata.org/pandas-docs/version/0.22/api.html)\n",
    "-  [Matplotlib](https://matplotlib.org/2.1.1/api/index.html)\n",
    "-  [Seaborn](http://seaborn.pydata.org/api.html)\n",
    "\n",
    "Once you are done, save this notebook and rename it as follows:\n",
    "\n",
    "<code>**YOURUSERNAME_2019-02-21.ipynb**</code>\n",
    "\n",
    "where <code>**YOURUSERNAME**</code> is your actual username. To be consistent, we are expecting your username to be composed by your first name's initial, followed by your full lastname. As an example, in my case this notebook must be saved as <code>**gtolomei_2019-02-21.ipynb**</code> (Remember to insert an underscore <code>**'_'**</code> between your username and the date).<br />\n",
    "\n",
    "Finally, go back to the [Moodle](https://elearning.studenti.math.unipd.it/esami/mod/assign/view.php?id=475) web page of the \"**2019-02-21 Python Programming Exam**\"; there, you will be able to upload your notebook file for grading.\n",
    "\n",
    "<center><h3>Submissions are allowed until <span style=\"color:red\">Thursday, 21 February 2019 at 10:45 AM</span></h3></center>\n",
    "\n",
    "Note that there is no limit on the number of submissions; however, be careful when you upload a new version of this notebook because each submission overwrites the previous one. \n",
    "The due date indicated above is **strict**; after that, the system will not accept any more submissions and the latest uploaded notebook will be the one considered for grading.\n",
    "\n",
    "The archive you have downloaded (<code style=\"color:magenta\">**2019-02-21-exam.tar**</code>) is orgaized as follows:\n",
    "\n",
    "<code style=\"color:red\">**2019-02-21-exam**</code> (root)<br />\n",
    "|----<code style=\"color:green\">**2019-02-21.ipynb**</code> (_this_ notebook)<br />\n",
    "|----<code>**corpus.txt**</code> (the text corpus you will be using for answering general Python programming questions)<br />\n",
    "|----<code>**dataset.csv**</code> (the dataset you will be using for answering data science related questions)<br />\n",
    "|----<code>**README.txt**</code> (a description of the dataset above)\n",
    "\n",
    "<center><h3>... Now, sit back, relax, and do your best!</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Name** = Your _first name_ here\n",
    "\n",
    "**Last Name** = Your _last name_ here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "886cd1b9260f6b68d2f1aa73a6fce3c5",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Adding the following line, allows Jupyter Notebook to visualize plots\n",
    "# produced by matplotlib directly below the code cell which generated those.\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from nose.tools import assert_equal\n",
    "from operator import itemgetter\n",
    "\n",
    "EPSILON = .0000001 # tiny tolerance for managing subtle differences resulting from floating point operations\n",
    "\n",
    "TEXT_CORPUS_FILE = \"corpus.txt\"\n",
    "DATASET_FILE = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec33bddf64f15258e1d3a4acdcdc65c5",
     "grade": false,
     "grade_id": "part-1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: General Coding (16 points)\n",
    "\n",
    "For **Part 1**, you will be asked to use the list below - called <code>**corpus**</code> - which contains a list of text documents, where each document is represented by a lowercase string with no punctuation character whatsoever.<br /> \n",
    "Please, execute the cell right below to successfully load those documents into <code>**corpus**</code>, see a few sample documents, and then answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2aed6eb17e131fc815f2f071dd4b6404",
     "grade": false,
     "grade_id": "part-1-required",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# used to replace any punctuation symbol with an empty character ('')\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "# load each individual document as a lowercase string into the list of strings `corpus`\n",
    "corpus = [doc.strip().lower().translate(translator) for doc in open(TEXT_CORPUS_FILE)]\n",
    "# print out the first 5 documents loaded\n",
    "print(\"The following are the first 5 documents loaded out of a total of {} documents:\\n\".format(len(corpus)))\n",
    "print(\"\\n\".join(corpus[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79d4252ef11999ebc4c410abe64d64c4",
     "grade": false,
     "grade_id": "exercise-1-1-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1.1 (1 point)\n",
    "\n",
    "Implement the function <code>**avg_doc_length**</code>, which returns the **average length** calculated over the documents in the <code>**corpus**</code>.<br />\n",
    "We define the _length_ of a document the number of the tokens which the document string is made of; a _token_ is any substring which is separated from the other by a **whitespace character**, i.e., <code>**\" \"**</code>.\n",
    "\n",
    "(**EXAMPLE:** If the document you are working with is the string <code>**\"I think therefore I am\"**</code>, then the corresponding tokens will be: <code>**\"I\"**</code>, <code>**\"think\"**</code>, <code>**\"therefore\"**</code>, <code>**\"I\"**</code>, and <code>**\"am\"**</code> thereby the length of this document will be **5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9d8e4e06d5af7f83c5b6d651383a6d64",
     "grade": false,
     "grade_id": "exercise-1-1-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def avg_doc_length():\n",
    "    \"\"\"\n",
    "    Returns the average length calculated over the documents in the `corpus`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40179e2a5f842a58d78d749829f77b3f",
     "grade": true,
     "grade_id": "exercise-1-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `avg_doc_length` function\n",
    "\"\"\"\n",
    "\n",
    "# Tests\n",
    "assert_equal(True, avg_doc_length() < 15.6)\n",
    "assert_equal(True, avg_doc_length() >= 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d25edcc84c6041c78ccda47a761cca46",
     "grade": false,
     "grade_id": "exercise-1-2-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1.2 (3 points)\n",
    "\n",
    "Implement the function <code>**is_word_in_doc**</code>, which takes as input a string <code>**word**</code> and and integer <code>**doc_id**</code>, and returns <code>**True**</code> if and only if the token <code>**word**</code> appears in the document <code>**doc_id**</code>. By convention, documents are identified by their index position in the <code>**corpus**</code> list, therefore the first element of the list will correspond to <code>**doc_id = 0**</code>, the second to <code>**doc_id = 1**</code>, and so on and so forth.<br />\n",
    "The function must be _case-insensitive_, meaning that <code>**is_word_in_doc(\"galileo\", 42) = is_word_in_doc(\"Galileo\", 42) = is_word_in_doc(\"GALILEO\", 42)**</code>. Finally, if the input <code>**doc_id**</code> is outside of its valid range $[0, N-1]$ (where $N$ is the total number of documents in the <code>**corpus**</code> list), the function should immediately return <code>**False**</code>.\n",
    "\n",
    "(**NOTE:** Words of documents contained in the <code>**corpus**</code> list are already lowercased, but there is no restiction on the <code>**word**</code> input to the <code>**is_word_in_doc**</code> function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "37718ce52662b8c06a9bee523c7fedac",
     "grade": false,
     "grade_id": "exercise-1-2-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def is_word_in_doc(word, doc_id):\n",
    "    \"\"\"\n",
    "    Return True iff the string `word` appears within the document `doc_id`, False otherwise.\n",
    "    Plus, it returns False whenever `doc_id` is outside of its valid range of values [0, N-1] (N = len(corpus))\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9e06360e2f2f0554e8f29e23676c0a36",
     "grade": true,
     "grade_id": "cell-1-2-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `is_word_in_doc` function\n",
    "\"\"\"\n",
    "\n",
    "# Tests\n",
    "assert_equal(True, is_word_in_doc(\"network\", 4))\n",
    "assert_equal(False, is_word_in_doc(\"Cable\", 198))\n",
    "assert_equal(False, is_word_in_doc(\"emails\", 73))\n",
    "assert_equal(True, is_word_in_doc(\"EMAIL\", 73))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8e893c9b8ee16d63be51c20230343fb",
     "grade": false,
     "grade_id": "exercise-1-3-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1.3 (5 points)\n",
    "\n",
    "Implement the function <code>**doc_stats**</code>, which returns a custom data structure, i.e., dictionary, where each key is a <code>**doc_id**</code> and each value is a tuple containing the <code>**min**</code>, <code>**max**</code>, <code>**mean**</code>, and <code>**standard deviation**</code> (in this very specific order) of the number of characters of the words which _that_ <code>**doc_id**</code> is made of.<br />\n",
    "For example, if the document is <code>\"I have been to Chargoggagoggmanchauggagoggchaubunagungamaugg lake last summer\"</code>, then:\n",
    "-  <code>**min = 1**</code>\n",
    "-  <code>**max = 45**</code>\n",
    "-  <code>**mean = 8.75**</code>\n",
    "-  <code>**std_dev = 13.77**</code>\n",
    "\n",
    "(**NOTE:** The _Chargoggagoggmanchauggagoggchaubunagungamaugg_ lake truly exists, and is located in Webster, Massachussets, USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d9ef1421bb001f48be8759ef0acaf7d5",
     "grade": false,
     "grade_id": "exercise-1-3-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def doc_stats():\n",
    "    \"\"\"\n",
    "    Returns a dictionary where each key is a `doc_id` and each value is a tuple containing \n",
    "    the min, max, mean, and standard deviation of the number of characters of each word for that document.\n",
    "    \"\"\"\n",
    "    doc_stats = {} # This is the variable that needs to be returned\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return doc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e759e26e2779c103cad09fd0879e9b30",
     "grade": true,
     "grade_id": "exercise-1-3-test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `doc_stats` function\n",
    "\"\"\"\n",
    "\n",
    "# Call off the function implemented above\n",
    "stats = doc_stats()\n",
    "\n",
    "# Tests\n",
    "assert_equal(2, stats[0][0])\n",
    "assert_equal(11, stats[0][1])\n",
    "assert_equal(True, np.abs(7.25 - stats[0][2]) < EPSILON)\n",
    "assert_equal(True, np.abs(3.2691742076555053 - stats[0][3]) < EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "00e8cf2e5af92e93989b02ddd59099b8",
     "grade": false,
     "grade_id": "exercise-1-4-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1.4 (7 points)\n",
    "\n",
    "Implement the function <code>**get_most_similar_docs**</code>, which takes as input a document identifier <code>**doc_i**</code> and an integer <code><b>n</b></code> (<code>**n > 0**</code>), and returns an **ordered list of pairs**, where each pair is as follows: $(doc_j, sim_{i,j}), (j\\neq i)$, i.e., the first element is a document identifier, whilst the second is the value of **Jaccard_similarity** computed between the set of $n$-grams of <code>**doc_i**</code> and <code>**doc_j**</code>. Such a list must be sorted by similarity (in not-ascending order) and by document identifier (in not-descending order).<br />\n",
    "To compute Jaccard similarity between any two documents you firstly have to extract word $n$-grams out of those documents. For example, if the string document is <code>\"I really like python programming\"</code> then:\n",
    "-  **bi-grams** ($n$ = 2): <code>**[(\"I\", \"really\"), (\"really\", \"like\"), (\"like\", \"python\"), (\"python\", \"programming\")]**</code>\n",
    "-  **tri-grams** ($n$ = 3): <code>**[(\"I\", \"really\", \"like\"), (\"really\", \"like\", \"python\"), (\"like\", \"python\", \"programming\")]**</code>\n",
    "-  ...\n",
    "\n",
    "Finally, suppose $A$ and $B$ represents the sets of $n$-grams as extracted from <code>**doc_i**</code> and another document in the corpus <code>**doc_j**</code>, respectively. Then, the Jaccard similarity between $A$ and $B$ is computed as follows:\n",
    "$$\n",
    "J(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "**SUGGESTIONS:** Implement the following **two** helper functions: \n",
    "-  <code>**n_grams(doc, n)**</code> which takes as input the string representing a document and an integer <code><b>n</b></code> (<code>**n > 0**</code>), and extracts the $n$-grams from it, $n =$ <code>**n**</code> (pay attention to how the \"sliding window\" should move across the string in order to extract the corresponding substrings...)\n",
    "-  <code>**jaccard_similarity(a, b)**</code> which takes as input two sets <code><b>a</b></code> and <code><b>b</b></code> and returns the Jaccard similarity as specified above (to avoid 0 division error, the function returns 0 if **both** <code><b>a</b></code> and <code><b>b</b></code> are empty.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0a72e917e833eeb7cff4312474b63c48",
     "grade": false,
     "grade_id": "exercise-1-4-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### SUGGESTION: Implement the function `n_grams` below which takes as input a string `doc` representing a document\n",
    "### and an integer n > 0, and returns a list of tuples containing the n-grams of `doc`\n",
    "def n_grams(doc, n):\n",
    "    n_grams = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return n_grams\n",
    "\n",
    "\n",
    "### SUGGESTION: Implement the function `jaccard_similarity` below which takes as input two sets `a` and `b`\n",
    "### and computes J = |a & b|/|a U b| (to avoid 0 division error, returns 0 if both a and b are empty)\n",
    "def jaccard_similarity(a, b):\n",
    "    if len(a) == 0 and len(b) == 0:\n",
    "        return 0\n",
    "    return len(set(a) & set(b))/len(set(a) | set(b))\n",
    "    \n",
    "\n",
    "def get_most_similar_docs(doc_i, n):\n",
    "    \"\"\"\n",
    "    Returns a list of pairs (doc_j, n_grams_jaccard(doc_i, doc_j) [doc_i != doc_j] \n",
    "    sorted by n_grams_jaccard (from the highest to the lowest) and by doc_id.\n",
    "    \"\"\"\n",
    "    most_similar_docs = [] # This is the variable that you shall return\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return most_similar_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a844f0b3a36e40facb351fa17cd864b1",
     "grade": true,
     "grade_id": "exercise-1-4-test",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `get_most_similar_docs` function\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(249, get_most_similar_docs(569, 2)[0][0])\n",
    "assert_equal(True, np.abs(0.21428571428571427 - get_most_similar_docs(569, 2)[0][1]) < EPSILON)\n",
    "assert_equal(504, get_most_similar_docs(27, 1)[1][0])\n",
    "assert_equal(True, np.abs(0.2 - get_most_similar_docs(27, 1)[1][1]) < EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b35fc80e57c4551152f097e167961b11",
     "grade": false,
     "grade_id": "part-2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: Data Science (16 points)\n",
    "\n",
    "In this part, you will be working with the dataset file <code>**dataset.csv**</code>. For a complete description of this data source, please refer to the <code>**README.txt**</code> file included in the archive.\n",
    "In a nutshell, this dataset contains **721** unique Pokemons, including their number (ID), name, first and second type, and basic stats: HP, Attack, Defense, Special Attack, Special Defense, and Speed. Finally, it also shows whether the Pokemon is \"legendary\" or not.<br />\n",
    "The cell below is responsible for correctly loading the dataset from the <code>**dataset.csv**</code> file. Once this is executed, you can start answering the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a57c21865493bd7d09fc331f64bc1787",
     "grade": false,
     "grade_id": "part-2-required",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset stored at `DATASET_FILE` using \",\" as field separator and '?' to detect NAs\n",
    "# and the specified columns as header\n",
    "\n",
    "# column names used as header\n",
    "colnames = ['id', 'name', 'type_1', 'type_2', 'total', 'hp', 'attack', 'defense', \n",
    "            'special_attack', 'special_defense', 'speed', 'generation', 'is_legendary']\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv(DATASET_FILE, \n",
    "                   sep=',',\n",
    "                   header=0,\n",
    "                   names=colnames,\n",
    "                   na_values='?')\n",
    "\n",
    "# remove any duplicates\n",
    "data = data.drop_duplicates('id', keep='first', inplace=False)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Loaded `Pokemon` dataset into a dataframe of size ({} x {})\".format(data.shape[0], data.shape[1]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "302f82a7bb2bca90a6c0db0ec0ba7afc",
     "grade": false,
     "grade_id": "exercise-2-1-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2.1 (1 point)\n",
    "\n",
    "Implement the function <code>**get_the_quickest**</code> below. This takes as input a <code>**pandas.DataFrame**</code> object, and returns the record (i.e., the <code>**pandas.Series**</code>) of the quickest Pokemon in the collection (i.e., the one with the highest <code>**speed**</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8b189b2981dfb0b31f3ef3fb601da472",
     "grade": false,
     "grade_id": "exercise-2-1-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_the_quickest(data):\n",
    "    \"\"\"\n",
    "    Returns the record of the quickest Pokemon in the collection (i.e., the one with the highest speed)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be651953a593f15818ceff5c49d629de",
     "grade": true,
     "grade_id": "exercise-2-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `get_the_quickest` function\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(\"Ninjask\", get_the_quickest(data)['name'].iloc[0])\n",
    "assert_equal(45, get_the_quickest(data)['defense'].iloc[0])\n",
    "assert_equal(\"Bug\", get_the_quickest(data)['type_1'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b71481945beb82fd5328d275ccedbad0",
     "grade": false,
     "grade_id": "exercise-2-2-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2.2 (3 points)\n",
    "\n",
    "Implement the function <code>**attack_stats**</code> below. This takes as input a <code>**pandas.DataFrame**</code> object and returns a tuple containing the min, max, avg, and median value of <code>**attack**</code> feature, yet computed on a _slice_ of the input <code>**pandas.DataFrame**</code>.<br />\n",
    "The sliced dataset represents the subpopulation containing **legendary** Pokemons whose speed is **strictly above the overall average**, and whose defense ranges in $[52, 73)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "98765ad5e3bde5fad3b12dc270e932fc",
     "grade": false,
     "grade_id": "exercise-2-2-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def attack_stats(data):\n",
    "    \"\"\"\n",
    "    Returns a tuple containing the min, max, avg, and median value of `attack` feature,\n",
    "    yet limited to a slice of the input DataFrame (data). \n",
    "    In particular, this slice will contain instances referring to legendary Pokemons\n",
    "    whose speed is strictly above the overall average, and whose defense ranges in [52,73).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75c2bfdf0dba6b1eba69f40cfc76e8a7",
     "grade": true,
     "grade_id": "exercise-2-2-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `attack_stats` function\n",
    "\"\"\"\n",
    "\n",
    "# Call off `attack_stats` function\n",
    "stats = attack_stats(data)\n",
    "\n",
    "assert_equal(90, stats[0])\n",
    "assert_equal(125, stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e76ef9e25a6fa18eb96fa0967aef5ea5",
     "grade": false,
     "grade_id": "exercise-2-3-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2.3 (5 points)\n",
    "\n",
    "Implement the function <code>**get_top_k_strongest**</code> below, which takes as input a <code>**pandas.DataFrame**</code> and an integer <code><b>k</b></code>, and returns the top-<code><b>k</b></code> Pokemon's <code>**type_1**</code> with the **highest average strength**. The overall strength is provided by the <code>**total**</code> column, as it contains a summary of all the statistics described in the other available columns.\n",
    "\n",
    "(**SUGGESTION:** In order to answer this question, you will need to compute the average strength for each group of Pokemon's <code>**type_1**</code>...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c549b5bcb9b0532c6c10302fea45a53",
     "grade": false,
     "grade_id": "exercise-2-3-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k_strongest(data, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "81f4a99bf968146e669555bbdaa0b277",
     "grade": true,
     "grade_id": "exercise-2-3-test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `get_top_k_strongest` function\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(5, len(get_top_k_strongest(data, 5)))\n",
    "assert_equal('Steel', get_top_k_strongest(data, 3)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "078359a02c74006c5c57c79ed11339e1",
     "grade": false,
     "grade_id": "exercise-2-4-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2.4 (7 points)\n",
    "\n",
    "This exercise is made of **3** main questions, which you can answer independently to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8225a2b4d41272330b7bd9d729736176",
     "grade": false,
     "grade_id": "exercise-2-4-1-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1 (1 point)\n",
    "\n",
    "Feature <code>**generation**</code> represents an ordinal (numerical) variable which can take on <b>6</b> distinct values.\n",
    "Assign to the variable <code>**lowest_generation**</code> below the total number of first-generation Pokemons in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "df343bcf8b03cf51b22c9557f0072a46",
     "grade": false,
     "grade_id": "exercise-2-4-1-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "lowest_generation = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e55c1568ee0550ab357762829c755cb8",
     "grade": true,
     "grade_id": "exercise-2-4-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the `lowest_generation`\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(False, (lowest_generation == None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1dfcf0c40eb7db2657f30ea678edd9aa",
     "grade": false,
     "grade_id": "exercise-2-4-2-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2 (3 points)\n",
    "\n",
    "Plot the regression line of <code>**special_attack**</code> ($x$-axis, independent variable) against <code>**special_defense**</code> ($y$-axis, dependent variable) using <code>**sns.regplot**</code> and assign the result of the plot to the variable <code>**reg_plot**</code>. \n",
    "\n",
    "In addition to that, assign to the variable <code>**pearson_r**</code> the Pearson's correlation coefficient computed between the two random varibles (<code>**special_attack**</code> and <code>**special_defense**</code>). This can be computed by calling the <code>**pearsonr**</code> scipy's built-in function, which takes as input the two random variables and returns a **pair**: the first item is the Pearson's correlation coefficient, whilst the second item is the $p$-value associated to the computed statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "64b34566504756769710f8fd341297a0",
     "grade": false,
     "grade_id": "exercise-2-4-2-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "reg_plot = None # assign this to the outcome of sns.regplot call\n",
    "pearson_r = None # assign this to value of the Pearson's correlation coefficient\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "47cfa7c0a060f393931d6917eefa70bb",
     "grade": true,
     "grade_id": "exercise-2-4-2-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of `reg_plot` and `pearson_r`\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(False, (reg_plot == None))\n",
    "assert_equal(False, (pearson_r == None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60594ae8967bd7cdd3c31a04fbdeda87",
     "grade": false,
     "grade_id": "exercise-2-4-3-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3 (3 points)\n",
    "\n",
    "Plot the boxplot of how the variable <code>**speed**</code> is distributed across each of the <b>6</b> generations of Pokemons using <code>**sns.boxplot**</code> function. Then, assign to the list variable <code>**outliers**</code> (initially empty, i.e., <code>**outliers = []**</code>) the values of Pokemon generations which exhibit _any_ outlier. For example, if generations <b>1</b>, <b>3</b>, and <b>5</b> show some outliers then you should make the following assignment: <code>**outliers = [1, 3, 5]**</code> (order **doesn't** matter!).\n",
    "\n",
    "(**NOTE:** If there is no outlier in any Pokemon generation then you should leave the list <code>**outliers**</code> empty as it originally is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "86c7815b415c035db07a080d246d7801",
     "grade": false,
     "grade_id": "exercise-2-4-3-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "box_plot = None # assign this to the outcome of sns.boxplot call\n",
    "outliers = [] # change this according to the resulting box plot!\n",
    "\n",
    "# Create a Figure containing 1x1 subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "# Box plot 'speed' against 'generation'\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "294459db3e0a60c2aef915f1a4fcf7ba",
     "grade": true,
     "grade_id": "exercise-2-4-3-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of `box_plot` and `outliers`\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(False, (box_plot == None))\n",
    "assert_equal(False, (outliers == None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
